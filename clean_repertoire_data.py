import pandas as pd
import numpy as np
import itertools
import os


def create_repertoire_dataframe(patient_id):
    '''Takes the patient_id string (e.g. 'YF189') as an arg and converts that
    patient's repertoire data file to a dataframe and returns the dataframe
    (could be modified to take full name of data file as an input instead)'''

    NumInClone_D0 = 'NumInClone_' + patient_id + 'D0'
    NumInClone_D7 = 'NumInClone_' + patient_id + 'D7'
    NumInClone_D14 = 'NumInClone_' + patient_id + 'D14'
    NumInClone_D28 = 'NumInClone_' + patient_id + 'D28'

    file_path = os.getcwd() + os.sep + 'inputs' + os.sep + 'repertoire_data' \
                + os.sep + 'Pacbio_Oct19_lib_' + patient_id \
                + '_withClones_collapsedByCell_annotated_withCellType.txt'

    # reads file and converts to dataframe
    df = pd.read_csv(
        file_path,
        sep='\t',
        low_memory=False,
        usecols=[
            'CloneID',
            'Seq_ID',
            'SampleID',
            'Class',
            'UCI',
            'UseAsRef',
            NumInClone_D0 ,
            NumInClone_D7,
            NumInClone_D14,
            NumInClone_D28]
        )

    # renames some columns
    df = df.rename(columns={
        'Seq_ID': 'SeqID',
        'UCI': 'CellID',
        NumInClone_D0: 'NumInClone_D0',
        NumInClone_D7: 'NumInClone_D7',
        NumInClone_D14: 'NumInClone_D14',
        NumInClone_D28: 'NumInClone_D28'})

    # converts 'sample_id' values to interger values of the sample day
    df['Day'] = df.SampleID.str[6:].fillna(0).astype(int)

    return df


def prepare_repertoire_dataframe(patient_id):
    '''Performs initial clean on dataframe generated by
    'create_repertoire_dataframe' function to prepare for future functions'''

    df = create_repertoire_dataframe(patient_id)

    # removes rows which contain NaN values for a subset of columns
    # (could change to all columns)
    df = df[pd.notnull(df.CloneID)]
    df = df[pd.notnull(df.Class)]
    df = df[pd.notnull(df.CellID)]

    # converts 'clone_id' values from floats to intergers
    df.CloneID = df.CloneID.astype(int)

    # sorts dataframes by ascending order of 'CloneID' then 'Day' values
    df = df.sort_values(['CloneID', 'Day']).reset_index()

    return df


def create_sequence_dataframe(patient_id):
    '''Takes the patient_id string (e.g. 'YF189') as an arg and converts that
    patient's sequence data file to a dataframe and returns the dataframe
    (could be modified to take full name of data file as an input instead)'''


    # can change to name of your sequence alignment data file
    file_path = os.getcwd() + os.sep + 'inputs' + os.sep + 'sequence_data' \
                + os.sep + patient_id + '_sequence_data.tsv'

    # reads file and converts to dataframe
    df = pd.read_csv(
    file_path,
    sep='\t',
    low_memory=False,
    usecols=[
        'sequence_id',
        'sequence_alignment_aa',
        'v_sequence_alignment_aa',
        'germline_alignment_aa',
        'v_germline_alignment_aa',
        'v_score',
        'v_identity',
        'productive'])

    return df


def prepare_sequence_dataframe(patient_id):
    '''Performs initial clean on dataframe generated by
    'create_sequence_dataframe' function to prepare for future functions'''

    df = create_sequence_dataframe(patient_id)

    # removes rows which contain NaN values for a subset of columns
    # (could change to all columns)
    df = df[pd.notnull(df.sequence_alignment_aa)]

    return df


def chain_type(Class):
    '''Given a single character string representing the class of the antibody
    chain as an arg, returns the chain type (heavy or light) as a string or 'na'
    if the character is not a known class'''

    if Class in ['L', 'K']:
        return 'light'
    elif Class in ['A', 'M', 'G']:
        return 'heavy'
    else:
        return 'na'


def get_paired_cells(patient_id):
    '''Takes a dataframe with the columns 'UCI', 'Day', and 'Class' as an arg
    and finds those 'CellID' values which are associated with 1 'Class' value
    corresponding to a 'heavy' chain type and 1 'Class' value corresonding to a
    'light' chain type. Returns a list of those 'CellID' values which
    satisfy these conditions'''

    # runs 'create_repertoire_dataframe'
    df_repertoire = prepare_repertoire_dataframe(patient_id)

    # runs 'create_sequence_dataframe'
    df_sequence = prepare_sequence_dataframe(patient_id)

    # sorts 'df_repertoire' by ascending 'CellID' values
    df_repertoire = df_repertoire.sort_values(['CellID']).reset_index(drop=True)

    # sets up empty, temporary dictionary and lists for use in the for loops
    d = {}
    paired_CellID_list = []
    ignore_CellID_list = []

    # creates a dictionary which counts the number of heavy and light 'Class'
    # values associated with each 'CellID' value and the 'Day' on which the last
    # counted 'Class' value appears
    for row in df_repertoire.itertuples():
        if row.CellID not in ignore_CellID_list:
            if row.CellID not in d:
                if chain_type(row.Class) == 'heavy':
                    d[row.CellID] = {'count': 1,
                                     'heavy_count': 1,
                                     'light_count': 0,
                                     'heavy_day': row.Day,
                                     'light_day': ''}
                elif chain_type(row.Class) == 'light':
                    d[row.CellID] = {'count': 1,
                                     'heavy_count': 0,
                                     'light_count': 1,
                                     'heavy_day': '',
                                     'light_day': row.Day}
                else:
                    ignore_CellID_list.append(row.CellID)
            else:
                if chain_type(row.Class) == 'heavy':
                    d[row.CellID]['count'] += 1
                    d[row.CellID]['heavy_count'] += 1
                    d[row.CellID]['heavy_day'] = row.Day
                elif chain_type(row.Class) == 'light':
                    d[row.CellID]['count'] += 1
                    d[row.CellID]['light_count'] += 1
                    d[row.CellID]['light_day'] = row.Day

    # checks if 'CellID' keys in dictionary 'd' are associated with only 1 heavy
    # and 1 light 'Class' value and that the days those values appear on are the
    # same and saves those 'CellID' values to a list
    for key in d:
        if (d[key]['count'] == 2) and (d[key]['heavy_count'] == 1) and (d[key]['light_count'] == 1) and (d[key]['heavy_day'] == d[key]['light_day']):
                paired_CellID_list.append(key)

    # filters 'df_repertoire' using paired_CellID_list
    df_repertoire = df_repertoire[df_repertoire.CellID.isin(paired_CellID_list)]

    # merges 'df_repertoire' and 'df_sequence' (may be CPU intensive)
    df = df_repertoire.merge(
        df_sequence, left_on='SeqID', right_on='sequence_id')

    # filters 'df' to only include rows where 'sequence_alignment_aa' values
    # contain '*' character(s) and saves 'CellID' values to 'remove_CellID_list'
    df = df[df.sequence_alignment_aa.str.contains('*', regex=False)]
    remove_CellID_list = list(df.CellID)

    # removes CellID values held in remove_CellID_list from paired_CellID_list
    paired_CellID_list = \
        [x for x in paired_CellID_list if x not in remove_CellID_list]

    return paired_CellID_list


def aggregate_dataframe(patient_id):

    # runs 'create_repertoire_dataframe'
    df = prepare_repertoire_dataframe(patient_id)

    # drops 'SeqID' column
    df = df.drop(['SeqID', 'UseAsRef'], axis=1)

    # creates new column 'no_cells for later use'
    df['no_cells'] = df.CellID

    # converts the 'NumInClone*' columns to new column 'no_seqs'
    df_agg = df         .groupby(['CloneID', 'Day', 'Class'], as_index=False)         .agg({
            'NumInClone_D0': 'max',
            'NumInClone_D7': 'max',
            'NumInClone_D14': 'max',
            'NumInClone_D28': 'max'})
    df_agg['no_seqs'] = df_agg.iloc[:, -5:].sum(axis=1).fillna(0).astype(int)

    # collapses rows by clone_id and creates new column 'no_cells' which shows number of cell_ids associated with clone_id
    df_temp1 = df_agg.groupby(['CloneID', 'Day', 'no_seqs']).agg({'Class': ', '.join}).reset_index()
    df_temp1 = df_temp1[['CloneID', 'Day', 'Class', 'no_seqs']]
    df_temp2 = df.groupby(['CloneID', 'Day']).agg({'no_cells': 'count'}).reset_index()
    df_agg = pd.merge(df_temp1, df_temp2, how='left', on=['CloneID', 'Day'])
    df_agg.no_cells = df_agg.no_cells.fillna(0).astype(int)

    # creates new column
    df_temp3 = df[df.CellID.isin(get_paired_cells(patient_id))]
    df_temp3 = df_temp3.groupby(['CloneID', 'Day']).agg({'CellID': 'count'}).reset_index()
    df_agg = pd.merge(df_agg, df_temp3, how='outer', on=['CloneID', 'Day']).rename(columns={'CellID': 'no_paired_cells'})
    df_agg.no_paired_cells = df_agg.no_paired_cells.fillna(0).astype(int)

    return df_agg


def get_top_heavy_clones(patient_id, threshold_percentage = 0.2):

    # runs 'aggregate_dataframe'
    df = aggregate_dataframe(patient_id)

    # filters dataframe to only include 'CloneID' values associated with heavy chain sequences that appear on 'Day' 7 or 14
    df_heavy = df[df.Class.isin(['A', 'G', 'M', 'A, G', 'A, M', 'G, M', 'A, G, M'])]
    df_heavy = df_heavy[['CloneID', 'Day', 'no_seqs']].reset_index(drop=True)
    df_heavy = df_heavy[(df_heavy.Day != 0) & (df_heavy.Day != 28)]
    df_heavy = df_heavy.groupby('CloneID').agg({'Day': 'sum', 'no_seqs': 'sum'}).reset_index()
    df_heavy = df_heavy.sort_values(by='no_seqs', ascending=False).reset_index(drop=True)
    print(len(df_heavy.CloneID.unique()))

    # converts threshold_percentage value to threshold 'no_seqs' value and filters dataframe
    threshold_actual = int(round(len(df_heavy) * threshold_percentage))
    df_heavy = df_heavy.head(threshold_actual)
    print(len(df_heavy.CloneID.unique()))

    # saves 'CloneID' values with highest 'no_seqs' values to a list
    top_heavy_CloneID_list = list(df_heavy.CloneID)

    return top_heavy_CloneID_list


def get_clone_statistics(patient_id, threshold_percentage = 0.2):

    df = aggregate_dataframe(patient_id)
    top_CloneID_list = get_top_heavy_clones(patient_id, threshold_percentage)

    # filters df using top_CloneID_list
    df_top_clones = df[df.CloneID.isin(top_CloneID_list)].reset_index(drop=True).copy()

    # filters dataframe to only include 'CloneID' values associated with heavy chain sequences that appear on 'Day' 7 or 14
    df_heavy = df[df.Class.isin(['A', 'G', 'M', 'A, G', 'A, M', 'G, M', 'A, G, M'])]
    df_heavy = df_heavy[['CloneID', 'Day', 'no_seqs']].reset_index(drop=True)
    df_heavy = df_heavy[(df_heavy.Day != 0) & (df_heavy.Day != 28)]
    df_heavy = df_heavy.groupby('CloneID').agg({'Day': 'sum', 'no_seqs': 'sum'}).reset_index()
    df_heavy = df_heavy.sort_values(by='no_seqs', ascending=False).reset_index(drop=True)

    # gets number of clones within threshold_percentage
    num_clones = int(round(len(df_heavy) * threshold_percentage))

    df = df_top_clones[['CloneID', 'no_paired_cells']]

    num_paired_seqs = df.no_paired_cells.sum()

    df = df.groupby('CloneID').agg({'no_paired_cells': 'sum'})

    no_modellable = np.count_nonzero(df['no_paired_cells'])


def get_top_paired_cells(patient_id):

    # runs 'create_repertoire_dataframe'
    df = prepare_repertoire_dataframe(patient_id)

    # drops the 'NumInClone*' columns
    df = df.drop(['NumInClone_D0', 'NumInClone_D7', 'NumInClone_D14', 'NumInClone_D28', 'UseAsRef'], axis=1)

    # filters dataframe for 'CloneID' values using 'get_top_heavy_clones' funtion
    df_top_heavy_clones = df[df.CloneID.isin(get_top_heavy_clones(patient_id))]

    # filters dataframe for 'CellID' values using 'CellID' values associated with 'CloneID' values from 'df_top_heavy_clones'
    # and 'CellID' values known as paired from 'get_paired_cells'
    df_top_cells = df[df.CellID.isin(list(df_top_heavy_clones.CellID))]
    df_top_cells = df_top_cells[df_top_cells.CellID.isin(get_paired_cells(patient_id))]

    # saves these 'CellID' values to a list
    top_paired_CellID_list = list(df_top_cells.CellID)

    return top_paired_CellID_list


def create_paired_cell_dataframe(patient_id):

    # runs 'create_repertoire_dataframe' function to get repertoire dataframe
    df_repertoire = prepare_repertoire_dataframe(patient_id)

    # filters 'df_repertoire' to only include rows where 'CellID' value appears in 'top_paired_CellID_list'
    top_paired_CellID_list = get_top_paired_cells(patient_id)
    df_repertoire = df_repertoire[df_repertoire.CellID.isin(top_paired_CellID_list)]

    # runs 'create_sequence_dataframe' function to get sequence alignment dataframe
    df_sequence = prepare_sequence_dataframe(patient_id)

    # removes '.' characters from 'sequence_alignment_aa' values for later submission to ABodyBuilder
    df_sequence.sequence_alignment_aa = df_sequence.sequence_alignment_aa.str.replace('.', '')

    # filters 'df_sequence' based on it's 'productive' column
    df_sequence = df_sequence[df_sequence.productive == 'T']

    # removes rows where 'sequence_alignment_aa' values contains '*' character(s)
    # to prevent errors when submitting to ABodyBuilder
    df_sequence = df_sequence[~df_sequence.sequence_alignment_aa.str.contains('*', regex=False)]

    # merges 'df_repertoire' and 'df_sequence' (may be CPU intensive)
    df = df_repertoire.merge(df_sequence, left_on='SeqID', right_on='sequence_id')

    # converts 'Class' values to 'Chain' values of either 'H' (heavy) or 'L' (light)
    df['Chain'] = df['Class'].replace({'A': 'H', 'G': 'H', 'M': 'H', 'K': 'L'})

    # drops unnecessary columns and sorts by ascending 'CellID' then 'Chain' values to show paired cell data
    df = df[['CellID', 'Chain', 'Class', 'sequence_alignment_aa', 'Day', 'CloneID', 'SeqID']].sort_values(['CellID', 'Chain', 'Day', 'CloneID']).reset_index(drop=True)

    return df


def reshape_paired_cell_dataframe(patient_id):

    # runs 'create_paired_cell_dataframe'
    df = create_paired_cell_dataframe(patient_id)

    # puts values associated with each 'CellID' value on same row
    df = df[['CellID', 'sequence_alignment_aa', 'CloneID', 'Class', 'Day', 'SeqID']]
    df = df.set_index(['CellID', df.groupby('CellID').cumcount()])[['sequence_alignment_aa', 'CloneID', 'Class', 'Day', 'SeqID']].unstack().reset_index()

    # copy multilevel columns to single level columns
    df['H_Seq'] = df['sequence_alignment_aa', 0]
    df['L_Seq'] = df['sequence_alignment_aa', 1]
    df['H_CloneID'] = df['CloneID', 0]
    df['L_CloneID'] = df['CloneID', 1]
    df['H_Class'] = df['Class', 0]
    df['L_Class'] = df['Class', 1]
    df['H_Day'] = df['Day', 0]
    df['L_Day'] = df['Day', 1]
    df['H_SeqID'] = df['SeqID', 0]
    df['L_SeqID'] = df['SeqID', 1]

    # creates new column 'jobname' for use when submitting to ABodyBuilder
    # value will be patient_id (e.g. 'YF189') + SampleID (e.g. D14) + '_' + CellID (e.g. AACACGTTCAGTTTGG)
    df['jobname'] = df['H_SeqID'].str.split('_').str[0] + '_' + df['H_SeqID'].str.split('_').str[3]

    # drop redundant multilevel columns
    df = df[[
        'CellID',
        'H_Seq',
        'L_Seq',
        'H_CloneID',
        'L_CloneID',
        'H_Class',
        'L_Class',
        'H_Day',
        'L_Day',
        'H_SeqID',
        'L_SeqID',
        'jobname']]
    df.columns = df.columns.droplevel(1)

    return df


def create_submission_dataframe(patient_id):

    # runs 'reshape_paired_cell_dataframe'
    df = reshape_paired_cell_dataframe(patient_id)

    # drops unnecessary columns
    df = df[['jobname', 'H_Seq', 'L_Seq']]

    # collapses rows with identical 'H_Seq' and 'L_Seq' values
    df = df.groupby(['H_Seq', 'L_Seq'], as_index=False).agg({'jobname': 'first'})

    # renames 'H_Seq' and 'L_Seq' columns for use in ABodyBuilder_python3 script
    df = df.rename(columns={'H_Seq': 'heavy_chain', 'L_Seq': 'light_chain'})[['jobname', 'heavy_chain', 'light_chain']]

    # creates empty column 'blacklist', required for ABodyBuilder_python3 script
    df['blacklist'] = ''

    return df


def save_submission_dataframes(patient_id_input):
    submission_path = os.getcwd() + os.sep + 'results' + os.sep + 'submission_files'
    if not os.path.exists(submission_path):
        os.makedirs(submission_path)
    if isinstance(patient_id_input, list):
        for patient_id in patient_id_input:
            df = create_submission_dataframe(patient_id)
            filepath = submission_path + os.sep + patient_id + '_submission_file.csv'
            df.to_csv(filepath, index=False)
    elif isinstance(patient_id_input, str):
        df = create_submission_dataframe(patient_id)
        filepath = submission_path + os.sep + patient_id + '_submission_file.csv'
        df.to_csv(filepath, index=False)
